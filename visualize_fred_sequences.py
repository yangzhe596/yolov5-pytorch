#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
FRED æ•°æ®é›†åºåˆ—å¯è§†åŒ–å·¥å…·

åŠŸèƒ½ï¼š
1. å¯è§†åŒ–æ•´ä¸ªè§†é¢‘åºåˆ—çš„æ ‡æ³¨
2. æ”¯æŒå¯¼å‡ºä¸ºè§†é¢‘æ–‡ä»¶
3. æ”¯æŒ RGB å’Œ Event ä¸¤ç§æ¨¡æ€
4. æ˜¾ç¤ºè¾¹ç•Œæ¡†ã€drone_idã€æ—¶é—´æˆ³ç­‰ä¿¡æ¯
5. æ”¯æŒé€‰æ‹©ç‰¹å®šåºåˆ—æˆ–éšæœºåºåˆ—

ä½¿ç”¨æ–¹æ³•ï¼š
    # å¯è§†åŒ–å•ä¸ªåºåˆ—å¹¶å¯¼å‡ºè§†é¢‘
    python visualize_fred_sequences.py --modality rgb --sequence 0 --export-video
    
    # å¯è§†åŒ–éšæœºåºåˆ—ï¼ˆä¸å¯¼å‡ºè§†é¢‘ï¼‰
    python visualize_fred_sequences.py --modality event --random
    
    # å¯è§†åŒ–å¤šä¸ªåºåˆ—
    python visualize_fred_sequences.py --modality rgb --sequences 0 1 5 --export-video
    
    # è‡ªå®šä¹‰è¾“å‡ºç›®å½•å’Œå¸§ç‡
    python visualize_fred_sequences.py --modality rgb --sequence 0 --export-video --output-dir visualizations --fps 30
"""

import os
import json
import argparse
import random
from pathlib import Path
from collections import defaultdict
import cv2
import numpy as np
from tqdm import tqdm
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class FREDSequenceVisualizer:
    """FRED åºåˆ—å¯è§†åŒ–å™¨"""
    
    def __init__(self, fred_root, coco_root, modality='rgb'):
        """
        åˆå§‹åŒ–å¯è§†åŒ–å™¨
        
        Args:
            fred_root: FRED æ•°æ®é›†æ ¹ç›®å½•
            coco_root: COCO æ ¼å¼æ•°æ®é›†æ ¹ç›®å½•
            modality: 'rgb' æˆ– 'event'
        """
        self.fred_root = Path(fred_root)
        self.coco_root = Path(coco_root)
        self.modality = modality.lower()
        
        if not self.fred_root.exists():
            raise FileNotFoundError(f"FRED æ ¹ç›®å½•ä¸å­˜åœ¨: {self.fred_root}")
        
        if not self.coco_root.exists():
            raise FileNotFoundError(f"COCO æ ¹ç›®å½•ä¸å­˜åœ¨: {self.coco_root}")
        
        # åŠ è½½ COCO æ ‡æ³¨
        self.annotations = self._load_all_annotations()
        
        # é¢œè‰²é…ç½®ï¼ˆBGR æ ¼å¼ï¼‰
        self.colors = {
            1: (0, 255, 0),    # drone_id 1: ç»¿è‰²
            2: (255, 0, 0),    # drone_id 2: è“è‰²
            3: (0, 0, 255),    # drone_id 3: çº¢è‰²
            4: (255, 255, 0),  # drone_id 4: é’è‰²
            5: (255, 0, 255),  # drone_id 5: å“çº¢è‰²
        }
        
        logger.info(f"åˆå§‹åŒ–å®Œæˆ - æ¨¡æ€: {self.modality}")
        logger.info(f"FRED æ ¹ç›®å½•: {self.fred_root}")
        logger.info(f"COCO æ ¹ç›®å½•: {self.coco_root}")
    
    def _load_all_annotations(self):
        """åŠ è½½æ‰€æœ‰åˆ’åˆ†çš„ COCO æ ‡æ³¨ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰"""
        logger.info("æ­£åœ¨åŠ è½½ COCO æ ‡æ³¨...")
        annotations = {}
        
        # ç¬¬ä¸€æ­¥ï¼šåˆ›å»ºå…¨å±€ image_id åˆ° sequence_id çš„æ˜ å°„
        image_id_to_seq = {}
        
        for split in ['train', 'val', 'test']:
            json_file = self.coco_root / self.modality / 'annotations' / f'instances_{split}.json'
            
            if not json_file.exists():
                logger.warning(f"æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {json_file}")
                continue
            
            logger.info(f"  åŠ è½½ {split} åˆ’åˆ†...")
            with open(json_file, 'r') as f:
                data = json.load(f)
            
            logger.info(f"    å›¾åƒæ•°: {len(data['images'])}, æ ‡æ³¨æ•°: {len(data['annotations'])}")
            
            # æŒ‰åºåˆ—ç»„ç»‡å›¾åƒæ•°æ®
            for img in data['images']:
                seq_id = img['sequence_id']
                if seq_id not in annotations:
                    annotations[seq_id] = {
                        'images': [],
                        'annotations': defaultdict(list)
                    }
                annotations[seq_id]['images'].append(img)
                image_id_to_seq[img['id']] = seq_id
            
            # ç»„ç»‡æ ‡æ³¨ï¼ˆä¼˜åŒ–ï¼šä½¿ç”¨å…¨å±€æ˜ å°„è¡¨ï¼ŒO(1) æŸ¥æ‰¾ï¼‰
            for ann in data['annotations']:
                img_id = ann['image_id']
                seq_id = image_id_to_seq.get(img_id)
                if seq_id is not None:
                    annotations[seq_id]['annotations'][img_id].append(ann)
        
        # æŒ‰æ—¶é—´æˆ³æ’åºæ¯ä¸ªåºåˆ—çš„å›¾åƒ
        logger.info("æ­£åœ¨æ’åºåºåˆ—...")
        for seq_id in annotations:
            annotations[seq_id]['images'].sort(key=lambda x: x['timestamp'])
        
        logger.info(f"âœ“ åŠ è½½å®Œæˆï¼å…± {len(annotations)} ä¸ªåºåˆ—")
        return annotations
    
    def get_available_sequences(self):
        """è·å–æ‰€æœ‰å¯ç”¨çš„åºåˆ— ID"""
        return sorted(self.annotations.keys())
    
    def get_sequence_info(self, sequence_id):
        """è·å–åºåˆ—ä¿¡æ¯"""
        if sequence_id not in self.annotations:
            return None
        
        seq_data = self.annotations[sequence_id]
        n_images = len(seq_data['images'])
        n_annotations = sum(len(anns) for anns in seq_data['annotations'].values())
        
        # è·å–æ—¶é—´èŒƒå›´
        timestamps = [img['timestamp'] for img in seq_data['images']]
        duration = max(timestamps) - min(timestamps) if timestamps else 0
        
        # è·å– drone_ids
        drone_ids = set()
        for anns in seq_data['annotations'].values():
            for ann in anns:
                drone_ids.add(ann.get('drone_id', 1))
        
        return {
            'sequence_id': sequence_id,
            'n_images': n_images,
            'n_annotations': n_annotations,
            'duration': duration,
            'drone_ids': sorted(drone_ids),
            'avg_annotations_per_image': n_annotations / n_images if n_images > 0 else 0
        }
    
    def visualize_sequence(self, sequence_id, export_video=False, output_dir='visualizations',
                          fps=30, show_window=True, max_frames=None):
        """
        å¯è§†åŒ–åºåˆ—
        
        Args:
            sequence_id: åºåˆ— ID
            export_video: æ˜¯å¦å¯¼å‡ºä¸ºè§†é¢‘
            output_dir: è¾“å‡ºç›®å½•
            fps: è§†é¢‘å¸§ç‡
            show_window: æ˜¯å¦æ˜¾ç¤ºçª—å£
            max_frames: æœ€å¤§å¸§æ•°ï¼ˆç”¨äºå¿«é€Ÿé¢„è§ˆï¼‰
        
        Returns:
            dict: å¯è§†åŒ–ç»Ÿè®¡ä¿¡æ¯
        """
        if sequence_id not in self.annotations:
            logger.error(f"åºåˆ— {sequence_id} ä¸å­˜åœ¨")
            return None
        
        seq_data = self.annotations[sequence_id]
        images = seq_data['images']
        
        original_count = len(images)
        if max_frames:
            images = images[:max_frames]
            logger.info(f"âš ï¸  å¿«é€Ÿé¢„è§ˆæ¨¡å¼ï¼šä»…å¤„ç†å‰ {max_frames} å¸§ï¼ˆå…± {original_count} å¸§ï¼‰")
        
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ¬ å¯è§†åŒ–åºåˆ— {sequence_id} ({self.modality.upper()} æ¨¡æ€)")
        logger.info(f"{'='*70}")
        logger.info(f"ğŸ“Š æ€»å¸§æ•°: {len(images)}")
        logger.info(f"ğŸ“¹ å¯¼å‡ºè§†é¢‘: {'æ˜¯' if export_video else 'å¦'}")
        logger.info(f"ğŸ–¥ï¸  æ˜¾ç¤ºçª—å£: {'æ˜¯' if show_window else 'å¦'}")
        if export_video:
            logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
            logger.info(f"ğŸï¸  å¸§ç‡: {fps} FPS")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        if export_video:
            output_path = Path(output_dir)
            output_path.mkdir(parents=True, exist_ok=True)
            logger.info(f"âœ“ è¾“å‡ºç›®å½•å·²åˆ›å»º: {output_path}")
            
            # è§†é¢‘è¾“å‡ºè·¯å¾„
            video_file = output_path / f"sequence_{sequence_id}_{self.modality}.mp4"
            
            # è·å–ç¬¬ä¸€å¸§ä»¥ç¡®å®šè§†é¢‘å°ºå¯¸
            logger.info("æ­£åœ¨è¯»å–ç¬¬ä¸€å¸§ä»¥ç¡®å®šè§†é¢‘å°ºå¯¸...")
            first_img_path = self.fred_root / images[0]['file_name']
            first_frame = cv2.imread(str(first_img_path))
            if first_frame is None:
                logger.error(f"âŒ æ— æ³•è¯»å–ç¬¬ä¸€å¸§: {first_img_path}")
                return None
            
            height, width = first_frame.shape[:2]
            logger.info(f"âœ“ è§†é¢‘åˆ†è¾¨ç‡: {width}x{height}")
            
            # åˆ›å»ºè§†é¢‘å†™å…¥å™¨
            logger.info("æ­£åœ¨åˆå§‹åŒ–è§†é¢‘ç¼–ç å™¨...")
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            video_writer = cv2.VideoWriter(str(video_file), fourcc, fps, (width, height))
            
            if not video_writer.isOpened():
                logger.error("âŒ æ— æ³•åˆ›å»ºè§†é¢‘å†™å…¥å™¨")
                return None
            
            logger.info(f"âœ“ è§†é¢‘å†™å…¥å™¨å·²å°±ç»ª")
            logger.info(f"ğŸ“¹ è¾“å‡ºæ–‡ä»¶: {video_file}")
        else:
            video_writer = None
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats = {
            'sequence_id': sequence_id,
            'total_frames': len(images),
            'frames_with_annotations': 0,
            'total_annotations': 0,
            'drone_ids': set()
        }
        
        # å¤„ç†æ¯ä¸€å¸§
        logger.info(f"å¼€å§‹å¤„ç† {len(images)} å¸§...")
        
        # åˆ›å»ºè¿›åº¦æ¡
        pbar = tqdm(images, desc=f"åºåˆ— {sequence_id}", 
                   bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]',
                   ncols=100)
        
        processed_frames = 0
        skipped_frames = 0
        
        for idx, img_info in enumerate(pbar):
            # è¯»å–å›¾åƒ
            img_path = self.fred_root / img_info['file_name']
            frame = cv2.imread(str(img_path))
            
            if frame is None:
                skipped_frames += 1
                if skipped_frames <= 5:  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
                    logger.warning(f"æ— æ³•è¯»å–å›¾åƒ: {img_path}")
                continue
            
            processed_frames += 1
            
            # æ›´æ–°è¿›åº¦æ¡æè¿°ï¼ˆå‡å°‘æ›´æ–°é¢‘ç‡ä»¥æå‡æ€§èƒ½ï¼‰
            if idx % 100 == 0:
                pbar.set_postfix({
                    'å·²å¤„ç†': processed_frames,
                    'è·³è¿‡': skipped_frames,
                    'æ—¶é—´': f"{img_info['timestamp']:.1f}s"
                })
            
            # è·å–è¯¥å¸§çš„æ ‡æ³¨
            img_id = img_info['id']
            annotations = seq_data['annotations'].get(img_id, [])
            
            if annotations:
                stats['frames_with_annotations'] += 1
                stats['total_annotations'] += len(annotations)
            
            # ç»˜åˆ¶æ ‡æ³¨ï¼ˆä¼˜åŒ–ï¼šå‡å°‘å‡½æ•°è°ƒç”¨ï¼‰
            for ann in annotations:
                drone_id = ann.get('drone_id', 1)
                stats['drone_ids'].add(drone_id)
                
                # è·å–è¾¹ç•Œæ¡† (COCO æ ¼å¼: [x, y, width, height])
                x, y, w, h = ann['bbox']
                x1, y1 = int(x), int(y)
                x2, y2 = int(x + w), int(y + h)
                
                # é€‰æ‹©é¢œè‰²
                color = self.colors.get(drone_id, (0, 255, 255))
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆä½¿ç”¨æ›´ç²—çš„çº¿æ¡ï¼Œæ›´æ˜æ˜¾ï¼‰
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                # ç»˜åˆ¶æ ‡ç­¾ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå‡å°‘ç»˜åˆ¶æ“ä½œï¼‰
                label = f"D{drone_id}"  # ç®€åŒ–æ ‡ç­¾
                cv2.putText(frame, label, (x1 + 5, y1 - 5),
                          cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)
            
            # æ·»åŠ ä¿¡æ¯æ–‡å­—ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            info_text = f"Seq:{sequence_id} Frame:{idx + 1}/{len(images)} Time:{img_info['timestamp']:.1f}s Obj:{len(annotations)}"
            
            # ç»˜åˆ¶ä¿¡æ¯é¢æ¿ï¼ˆå•è¡Œï¼Œæ›´ç®€æ´ï¼‰
            cv2.rectangle(frame, (10, 10), (600, 45), (0, 0, 0), -1)
            cv2.putText(frame, info_text, (20, 32),
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            
            # å†™å…¥è§†é¢‘ï¼ˆä¼˜åŒ–ï¼šæ‰¹é‡å†™å…¥å¯ä»¥æå‡æ€§èƒ½ï¼Œä½†OpenCVä¸æ”¯æŒï¼Œä¿æŒåŸæ ·ï¼‰
            if video_writer:
                video_writer.write(frame)
            
            # æ˜¾ç¤ºçª—å£ï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰
            if show_window and idx % 2 == 0:  # æ¯2å¸§æ˜¾ç¤ºä¸€æ¬¡ï¼Œå‡å°‘çª—å£åˆ·æ–°
                cv2.imshow(f'Sequence {sequence_id} - {self.modality.upper()}', frame)
                
                # æŒ‰ 'q' é€€å‡ºï¼ŒæŒ‰ 'p' æš‚åœ
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    logger.info("ç”¨æˆ·ä¸­æ–­")
                    break
                elif key == ord('p'):
                    logger.info("æš‚åœ - æŒ‰ä»»æ„é”®ç»§ç»­")
                    cv2.waitKey(0)
        
        # æ¸…ç†
        if video_writer:
            video_writer.release()
            file_size = video_file.stat().st_size / (1024 * 1024)  # MB
            logger.info(f"âœ“ è§†é¢‘å·²ä¿å­˜: {video_file} ({file_size:.1f} MB)")
        
        if show_window:
            cv2.destroyAllWindows()
        
        # å®Œå–„ç»Ÿè®¡ä¿¡æ¯
        stats['drone_ids'] = sorted(stats['drone_ids'])
        stats['annotation_rate'] = stats['frames_with_annotations'] / stats['total_frames'] if stats['total_frames'] > 0 else 0
        
        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        logger.info(f"\n{'='*70}")
        logger.info(f"åºåˆ— {sequence_id} ç»Ÿè®¡ä¿¡æ¯")
        logger.info(f"{'='*70}")
        logger.info(f"æ€»å¸§æ•°: {stats['total_frames']}")
        logger.info(f"æœ‰æ ‡æ³¨çš„å¸§: {stats['frames_with_annotations']} ({stats['annotation_rate']*100:.1f}%)")
        logger.info(f"æ€»æ ‡æ³¨æ•°: {stats['total_annotations']}")
        logger.info(f"å¹³å‡æ ‡æ³¨/å¸§: {stats['total_annotations']/stats['total_frames']:.2f}")
        logger.info(f"Drone IDs: {stats['drone_ids']}")
        logger.info(f"{'='*70}\n")
        
        return stats
    
    def visualize_multiple_sequences(self, sequence_ids, export_video=False, 
                                    output_dir='visualizations', fps=30, 
                                    show_window=True, max_frames=None):
        """
        å¯è§†åŒ–å¤šä¸ªåºåˆ—
        
        Args:
            sequence_ids: åºåˆ— ID åˆ—è¡¨
            export_video: æ˜¯å¦å¯¼å‡ºè§†é¢‘
            output_dir: è¾“å‡ºç›®å½•
            fps: è§†é¢‘å¸§ç‡
            show_window: æ˜¯å¦æ˜¾ç¤ºçª—å£
            max_frames: æ¯ä¸ªåºåˆ—çš„æœ€å¤§å¸§æ•°
        
        Returns:
            list: æ¯ä¸ªåºåˆ—çš„ç»Ÿè®¡ä¿¡æ¯
        """
        logger.info(f"\n{'='*70}")
        logger.info(f"ğŸ¬ æ‰¹é‡å¯è§†åŒ– - å…± {len(sequence_ids)} ä¸ªåºåˆ—")
        logger.info(f"{'='*70}")
        logger.info(f"åºåˆ—åˆ—è¡¨: {sequence_ids}")
        logger.info(f"{'='*70}\n")
        
        all_stats = []
        
        for idx, seq_id in enumerate(sequence_ids, 1):
            logger.info(f"\n>>> è¿›åº¦: [{idx}/{len(sequence_ids)}] å¤„ç†åºåˆ— {seq_id} <<<\n")
            stats = self.visualize_sequence(
                seq_id, 
                export_video=export_video,
                output_dir=output_dir,
                fps=fps,
                show_window=show_window,
                max_frames=max_frames
            )
            
            if stats:
                all_stats.append(stats)
        
        # æ‰“å°æ€»ä½“ç»Ÿè®¡
        if all_stats:
            logger.info(f"\n{'='*70}")
            logger.info(f"æ€»ä½“ç»Ÿè®¡ ({len(all_stats)} ä¸ªåºåˆ—)")
            logger.info(f"{'='*70}")
            
            total_frames = sum(s['total_frames'] for s in all_stats)
            total_annotations = sum(s['total_annotations'] for s in all_stats)
            all_drone_ids = set()
            for s in all_stats:
                all_drone_ids.update(s['drone_ids'])
            
            logger.info(f"æ€»å¸§æ•°: {total_frames}")
            logger.info(f"æ€»æ ‡æ³¨æ•°: {total_annotations}")
            logger.info(f"å¹³å‡æ ‡æ³¨/å¸§: {total_annotations/total_frames:.2f}")
            logger.info(f"æ‰€æœ‰ Drone IDs: {sorted(all_drone_ids)}")
            logger.info(f"{'='*70}\n")
        
        return all_stats
    
    def create_comparison_video(self, sequence_id, output_dir='visualizations', fps=30):
        """
        åˆ›å»º RGB å’Œ Event å¯¹æ¯”è§†é¢‘ï¼ˆéœ€è¦ä¸¤ç§æ¨¡æ€éƒ½å­˜åœ¨ï¼‰
        
        Args:
            sequence_id: åºåˆ— ID
            output_dir: è¾“å‡ºç›®å½•
            fps: è§†é¢‘å¸§ç‡
        
        Returns:
            str: è¾“å‡ºè§†é¢‘è·¯å¾„
        """
        logger.info(f"\nåˆ›å»ºå¯¹æ¯”è§†é¢‘ - åºåˆ— {sequence_id}")
        
        # æ£€æŸ¥ä¸¤ç§æ¨¡æ€æ˜¯å¦éƒ½å­˜åœ¨
        rgb_visualizer = FREDSequenceVisualizer(self.fred_root, self.coco_root, 'rgb')
        event_visualizer = FREDSequenceVisualizer(self.fred_root, self.coco_root, 'event')
        
        if sequence_id not in rgb_visualizer.annotations:
            logger.error(f"RGB æ¨¡æ€ä¸­ä¸å­˜åœ¨åºåˆ— {sequence_id}")
            return None
        
        if sequence_id not in event_visualizer.annotations:
            logger.error(f"Event æ¨¡æ€ä¸­ä¸å­˜åœ¨åºåˆ— {sequence_id}")
            return None
        
        # è·å–ä¸¤ç§æ¨¡æ€çš„å›¾åƒ
        rgb_images = rgb_visualizer.annotations[sequence_id]['images']
        event_images = event_visualizer.annotations[sequence_id]['images']
        
        # ä½¿ç”¨è¾ƒçŸ­çš„åºåˆ—
        n_frames = min(len(rgb_images), len(event_images))
        
        logger.info(f"RGB å¸§æ•°: {len(rgb_images)}, Event å¸§æ•°: {len(event_images)}")
        logger.info(f"ä½¿ç”¨ {n_frames} å¸§åˆ›å»ºå¯¹æ¯”è§†é¢‘")
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path = Path(output_dir)
        output_path.mkdir(parents=True, exist_ok=True)
        video_file = output_path / f"sequence_{sequence_id}_comparison.mp4"
        
        # è¯»å–ç¬¬ä¸€å¸§ä»¥ç¡®å®šå°ºå¯¸
        rgb_frame = cv2.imread(str(self.fred_root / rgb_images[0]['file_name']))
        event_frame = cv2.imread(str(self.fred_root / event_images[0]['file_name']))
        
        if rgb_frame is None or event_frame is None:
            logger.error("æ— æ³•è¯»å–ç¬¬ä¸€å¸§")
            return None
        
        h, w = rgb_frame.shape[:2]
        
        # åˆ›å»ºè§†é¢‘å†™å…¥å™¨ï¼ˆå®½åº¦ç¿»å€ï¼‰
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        video_writer = cv2.VideoWriter(str(video_file), fourcc, fps, (w * 2, h))
        
        logger.info(f"å¯¼å‡ºå¯¹æ¯”è§†é¢‘: {video_file}")
        logger.info(f"åˆ†è¾¨ç‡: {w*2}x{h}, å¸§ç‡: {fps} FPS")
        
        # å¤„ç†æ¯ä¸€å¸§
        logger.info(f"å¼€å§‹å¤„ç† {n_frames} å¸§...")
        
        pbar = tqdm(range(n_frames), desc="å¯¹æ¯”è§†é¢‘",
                   bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]')
        
        for idx in pbar:
            # RGB å¸§
            rgb_img_info = rgb_images[idx]
            rgb_path = self.fred_root / rgb_img_info['file_name']
            rgb_frame = cv2.imread(str(rgb_path))
            
            # Event å¸§
            event_img_info = event_images[idx]
            event_path = self.fred_root / event_img_info['file_name']
            event_frame = cv2.imread(str(event_path))
            
            if rgb_frame is None or event_frame is None:
                continue
            
            # æ›´æ–°è¿›åº¦
            if idx % 50 == 0:
                pbar.set_postfix({'æ—¶é—´': f"{rgb_img_info['timestamp']:.1f}s"})
            
            # ç»˜åˆ¶ RGB æ ‡æ³¨
            rgb_anns = rgb_visualizer.annotations[sequence_id]['annotations'].get(rgb_img_info['id'], [])
            for ann in rgb_anns:
                x, y, w_box, h_box = ann['bbox']
                drone_id = ann.get('drone_id', 1)
                color = self.colors.get(drone_id, (0, 255, 255))
                cv2.rectangle(rgb_frame, (int(x), int(y)), (int(x+w_box), int(y+h_box)), color, 2)
            
            # ç»˜åˆ¶ Event æ ‡æ³¨
            event_anns = event_visualizer.annotations[sequence_id]['annotations'].get(event_img_info['id'], [])
            for ann in event_anns:
                x, y, w_box, h_box = ann['bbox']
                drone_id = ann.get('drone_id', 1)
                color = self.colors.get(drone_id, (0, 255, 255))
                cv2.rectangle(event_frame, (int(x), int(y)), (int(x+w_box), int(y+h_box)), color, 2)
            
            # æ·»åŠ æ ‡ç­¾
            cv2.putText(rgb_frame, "RGB", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
            cv2.putText(event_frame, "EVENT", (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1.2, (255, 255, 255), 2)
            
            # åˆå¹¶å¸§
            combined_frame = np.hstack([rgb_frame, event_frame])
            
            # å†™å…¥è§†é¢‘
            video_writer.write(combined_frame)
        
        video_writer.release()
        file_size = Path(video_file).stat().st_size / (1024 * 1024)  # MB
        logger.info(f"âœ“ å¯¹æ¯”è§†é¢‘å·²ä¿å­˜: {video_file} ({file_size:.1f} MB)")
        
        return str(video_file)


def main():
    parser = argparse.ArgumentParser(
        description='FRED æ•°æ®é›†åºåˆ—å¯è§†åŒ–å·¥å…·',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # å¯è§†åŒ–å•ä¸ªåºåˆ—å¹¶å¯¼å‡ºè§†é¢‘
  python visualize_fred_sequences.py --modality rgb --sequence 0 --export-video
  
  # å¯è§†åŒ–éšæœºåºåˆ—ï¼ˆä¸å¯¼å‡ºè§†é¢‘ï¼‰
  python visualize_fred_sequences.py --modality event --random
  
  # å¯è§†åŒ–å¤šä¸ªåºåˆ—
  python visualize_fred_sequences.py --modality rgb --sequences 0 1 5 --export-video
  
  # åˆ›å»º RGB å’Œ Event å¯¹æ¯”è§†é¢‘
  python visualize_fred_sequences.py --comparison --sequence 0
  
  # å¿«é€Ÿé¢„è§ˆï¼ˆä»…å‰100å¸§ï¼‰
  python visualize_fred_sequences.py --modality rgb --sequence 0 --max-frames 100
  
  # åˆ—å‡ºæ‰€æœ‰å¯ç”¨åºåˆ—
  python visualize_fred_sequences.py --modality rgb --list-sequences
        """
    )
    
    parser.add_argument('--fred-root', type=str, 
                       default='/mnt/data/datasets/fred',
                       help='FRED æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--coco-root', type=str, 
                       default='datasets/fred_coco',
                       help='COCO æ ¼å¼æ•°æ®é›†æ ¹ç›®å½•')
    parser.add_argument('--modality', type=str, 
                       default='rgb',
                       choices=['rgb', 'event'],
                       help='æ¨¡æ€é€‰æ‹©')
    parser.add_argument('--sequence', type=int,
                       help='åºåˆ— ID')
    parser.add_argument('--sequences', type=int, nargs='+',
                       help='å¤šä¸ªåºåˆ— ID')
    parser.add_argument('--random', action='store_true',
                       help='éšæœºé€‰æ‹©ä¸€ä¸ªåºåˆ—')
    parser.add_argument('--export-video', action='store_true',
                       help='å¯¼å‡ºä¸ºè§†é¢‘æ–‡ä»¶')
    parser.add_argument('--output-dir', type=str, 
                       default='visualizations',
                       help='è¾“å‡ºç›®å½•')
    parser.add_argument('--fps', type=int, default=30,
                       help='è§†é¢‘å¸§ç‡')
    parser.add_argument('--no-window', action='store_true',
                       help='ä¸æ˜¾ç¤ºçª—å£ï¼ˆä»…å¯¼å‡ºè§†é¢‘ï¼‰')
    parser.add_argument('--max-frames', type=int,
                       help='æœ€å¤§å¸§æ•°ï¼ˆç”¨äºå¿«é€Ÿé¢„è§ˆï¼‰')
    parser.add_argument('--list-sequences', action='store_true',
                       help='åˆ—å‡ºæ‰€æœ‰å¯ç”¨åºåˆ—')
    parser.add_argument('--comparison', action='store_true',
                       help='åˆ›å»º RGB å’Œ Event å¯¹æ¯”è§†é¢‘')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºå¯è§†åŒ–å™¨
        visualizer = FREDSequenceVisualizer(
            fred_root=args.fred_root,
            coco_root=args.coco_root,
            modality=args.modality
        )
        
        # åˆ—å‡ºæ‰€æœ‰åºåˆ—
        if args.list_sequences:
            sequences = visualizer.get_available_sequences()
            logger.info(f"\nå¯ç”¨åºåˆ— ({len(sequences)} ä¸ª):")
            for seq_id in sequences:
                info = visualizer.get_sequence_info(seq_id)
                logger.info(f"  åºåˆ— {seq_id}: {info['n_images']} å¸§, "
                          f"{info['n_annotations']} æ ‡æ³¨, "
                          f"æ—¶é•¿ {info['duration']:.1f}s, "
                          f"Drones: {info['drone_ids']}")
            return 0
        
        # åˆ›å»ºå¯¹æ¯”è§†é¢‘
        if args.comparison:
            if not args.sequence:
                logger.error("åˆ›å»ºå¯¹æ¯”è§†é¢‘éœ€è¦æŒ‡å®š --sequence")
                return 1
            
            visualizer.create_comparison_video(
                sequence_id=args.sequence,
                output_dir=args.output_dir,
                fps=args.fps
            )
            return 0
        
        # ç¡®å®šè¦å¯è§†åŒ–çš„åºåˆ—
        if args.sequences:
            sequence_ids = args.sequences
        elif args.sequence is not None:
            sequence_ids = [args.sequence]
        elif args.random:
            available = visualizer.get_available_sequences()
            if not available:
                logger.error("æ²¡æœ‰å¯ç”¨çš„åºåˆ—")
                return 1
            sequence_ids = [random.choice(available)]
            logger.info(f"éšæœºé€‰æ‹©åºåˆ—: {sequence_ids[0]}")
        else:
            logger.error("è¯·æŒ‡å®š --sequence, --sequences, æˆ– --random")
            return 1
        
        # å¯è§†åŒ–åºåˆ—
        visualizer.visualize_multiple_sequences(
            sequence_ids=sequence_ids,
            export_video=args.export_video,
            output_dir=args.output_dir,
            fps=args.fps,
            show_window=not args.no_window,
            max_frames=args.max_frames
        )
        
        logger.info("\nâœ… å¯è§†åŒ–å®Œæˆï¼")
        return 0
        
    except Exception as e:
        logger.error(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == '__main__':
    exit(main())
