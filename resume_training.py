"""
Fusion æ¨¡å‹æ–­ç‚¹ç»­ç»ƒå·¥å…·

ç”¨äºä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒï¼Œé¿å…å› å´©æºƒæˆ–åœæ­¢å¯¼è‡´çš„æŸå¤±
"""
import os
import torch
import argparse
from train_fred_fusion import main as train_main


def find_latest_checkpoint(log_dir, phase="unfreeze"):
    """
    æŸ¥æ‰¾æœ€æ–°çš„æ£€æŸ¥ç‚¹
    
    Args:
        log_dir: æ—¥å¿—ç›®å½•
        phase: è®­ç»ƒé˜¶æ®µ ("freeze" æˆ– "unfreeze")
        
    Returns:
        æ£€æŸ¥ç‚¹è·¯å¾„æˆ– None
    """
    import re
    
    checkpoint_files = []
    for file in os.listdir(log_dir):
        if file.endswith('.pth') and phase in file:
            # æå– epoch æ•°å­—
            match = re.search(rf'{phase}_epoch_(\d+)_weights\.pth', file)
            if match:
                epoch = int(match.group(1))
                checkpoint_files.append((epoch, os.path.join(log_dir, file)))
    
    if not checkpoint_files:
        return None
    
    # æŒ‰ epoch é™åºæ’åºï¼Œè¿”å›æœ€æ–°çš„
    checkpoint_files.sort(reverse=True, key=lambda x: x[0])
    return checkpoint_files[0]  # (epoch, path)


def resume_training_from_checkpoint(args, checkpoint_path):
    """
    ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ
    
    Args:
        args: å‘½ä»¤è¡Œå‚æ•°
        checkpoint_path: æ£€æŸ¥ç‚¹è·¯å¾„
        
    Returns:
        updated_args: æ›´æ–°åçš„å‚æ•°
    """
    print("="*60)
    print(f"ä»æ£€æŸ¥ç‚¹æ¢å¤è®­ç»ƒ")
    print("="*60)
    print(f"æ£€æŸ¥ç‚¹: {checkpoint_path}")
    
    # åŠ è½½æ£€æŸ¥ç‚¹
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    start_epoch = checkpoint['epoch']
    
    print(f"æ¢å¤åˆ° epoch: {start_epoch}")
    
    # æ›´æ–°å‚æ•°
    args.resuming = True
    args.checkpoint_path = checkpoint_path
    
    return args, start_epoch


def main():
    """
    ä¸»å‡½æ•°ï¼šæä¾›å‘½ä»¤è¡Œæ¥å£ç”¨äºæ–­ç‚¹ç»­ç»ƒ
    """
    parser = argparse.ArgumentParser(description="Fusion æ¨¡å‹æ–­ç‚¹ç»­ç»ƒ")
    
    # åŸºæœ¬å‚æ•°
    parser.add_argument('--modality', type=str, default='rgb', 
                       choices=['rgb', 'event'], help='è®­ç»ƒæ¨¡æ€')
    parser.add_argument('--log_dir', type=str, default=None, 
                       help='æ—¥å¿—ç›®å½•è·¯å¾„ï¼ˆå¦‚æœä¸æŒ‡å®šï¼Œè‡ªåŠ¨æŸ¥æ‰¾ï¼‰')
    parser.add_argument('--resume_checkpoint', type=str, default=None,
                       help='æ‰‹åŠ¨æŒ‡å®šæ£€æŸ¥ç‚¹è·¯å¾„')
    
    # Fusion ç‰¹å®šå‚æ•°ï¼ˆé€ä¼ ç»™ train_fred_fusion.pyï¼‰
    mode_group = parser.add_argument_group('è®­ç»ƒæ¨¡å¼')
    mode_group.add_argument('--freeze_training', action='store_true',
                          help='ä»…è¿›è¡Œå†»ç»“è®­ç»ƒï¼Œä¸è¿›è¡Œè§£å†»è®­ç»ƒ')
    mode_group.add_argument('--no_eval', action='store_true',
                          help='ç¦ç”¨è¯„ä¼°')
    mode_group.add_argument('--no_eval_map', action='store_true',
                          help='ç¦ç”¨ mAP è¯„ä¼°')
    mode_group.add_argument('--quick_test', action='store_true',
                          help='å¿«é€Ÿæµ‹è¯•æ¨¡å¼')
    
    model_group = parser.add_argument_group('æ¨¡å‹é…ç½®')
    model_group.add_argument('--backbone', type=str, default='cspdarknet',
                           choices=['cspdarknet', 'convnext_tiny', 'convnext_small', 'swin_transformer_tiny'],
                           help='ä¸»å¹²ç½‘ç»œ')
    model_group.add_argument('--phi', type=str, default='s',
                           choices=['s', 'm', 'l', 'x'],
                           help='YOLOv5 ç‰ˆæœ¬')
    model_group.add_argument('--resume_last', action='store_true',
                           help='ä»æœ€åä¿å­˜çš„æ¨¡å‹æ¢å¤ï¼ˆä¸æ”¯æŒ checkpointï¼‰')
    
    # è§£æå‚æ•°
    args = parser.parse_args()
    
    # ç¡®å®šæ—¥å¿—ç›®å½•
    if args.log_dir is None:
        if args.modality == 'rgb':
            log_dir = 'logs/fred_rgb'
        else:
            log_dir = 'logs/fred_event'
    else:
        log_dir = args.log_dir
    
    print(f"\næ—¥å¿—ç›®å½•: {log_dir}")
    
    # æŸ¥æ‰¾æ£€æŸ¥ç‚¹
    checkpoint_path = None
    if args.resume_checkpoint:
        checkpoint_path = args.resume_checkpoint
        phase = "freeze" if "freeze" in checkpoint_path else "unfreeze"
    else:
        # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°æ£€æŸ¥ç‚¹ï¼ˆä¼˜å…ˆæŸ¥æ‰¾ unfreezeï¼‰
        checkpoint_path = find_latest_checkpoint(log_dir, "unfreeze")
        if checkpoint_path is None:
            checkpoint_path = find_latest_checkpoint(log_dir, "freeze")
        
        if checkpoint_path:
            phase = "freeze" if "freeze" in checkpoint_path[1] else "unfreeze"
            checkpoint_path = checkpoint_path[1]
    
    if checkpoint_path is None:
        print("âŒ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹æ–‡ä»¶")
        print(f"æ£€æŸ¥ç›®å½•: {log_dir}")
        return
    
    # æ›´æ–°å‚æ•°ä»¥æ”¯æŒæ–­ç‚¹ç»­ç»ƒ
    args.resuming = True
    args.checkpoint_path = checkpoint_path
    args.resume_last = False  # ä¸ä½¿ç”¨æœ€åä¿å­˜çš„æ¨¡å‹ï¼Œè€Œæ˜¯ä½¿ç”¨ checkpoint
    
    print(f"âœ“ ä½¿ç”¨æ£€æŸ¥ç‚¹: {checkpoint_path}")
    print(f"âœ“ è®­ç»ƒé˜¶æ®µ: {'å†»ç»“è®­ç»ƒ' if 'freeze' in checkpoint_path else 'è§£å†»è®­ç»ƒ'}")
    
    # åŠ è½½æ£€æŸ¥ç‚¹ä»¥è·å–èµ·å§‹ epoch
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    resume_epoch = checkpoint['epoch']
    print(f"âœ“ ä» epoch {resume_epoch} æ¢å¤è®­ç»ƒ")
    
    # æ˜¾ç¤ºæ¢å¤ä¿¡æ¯
    print("\n" + "="*60)
    print("æ–­ç‚¹ç»­ç»ƒé…ç½®")
    print("="*60)
    print(f"æ£€æŸ¥ç‚¹: {os.path.basename(checkpoint_path)}")
    print(f"èµ·å§‹ epoch: {resume_epoch}")
    print(f"è®­ç»ƒæ¨¡æ€: {args.modality.upper()}")
    if args.freeze_training:
        print(f"è®­ç»ƒæ¨¡å¼: å†»ç»“è®­ç»ƒï¼ˆä»…å†»ç»“é˜¶æ®µï¼‰")
    else:
        print(f"è®­ç»ƒæ¨¡å¼: å†»ç»“ + è§£å†»è®­ç»ƒ")
    
    # è°ƒç”¨ä¸»è®­ç»ƒå‡½æ•°
    # æ³¨æ„ï¼šéœ€è¦ä¿®æ”¹ train_fred_fusion.py ä»¥æ”¯æŒ checkpoint å‚æ•°
    print("\nâš ï¸  æ³¨æ„: è¿™åªæ˜¯ä¸€ä¸ªç¤ºä¾‹å®ç°")
    print("å®é™…ä½¿ç”¨æ—¶éœ€è¦:")
    print("1. ä¿®æ”¹ train_fred_fusion.py çš„å‚æ•°è§£æ")
    print("2. æ·»åŠ  --resume_checkpoint å‚æ•°æ”¯æŒ")
    print("3. åœ¨è®­ç»ƒå¼€å§‹æ—¶åŠ è½½ checkpoint")
    
    # æ„å»ºå‚æ•°åˆ—è¡¨
    argv = [
        '--modality', args.modality,
        '--resume_checkpoint', checkpoint_path
    ]
    
    if args.freeze_training:
        argv.append('--freeze_training')
    if args.no_eval:
        argv.append('--no_eval')
    if args.no_eval_map:
        argv.append('--no_eval_map')
    if args.quick_test:
        argv.append('--quick_test')
    
    return


def simple_resume_example():
    """
    ç®€å•çš„æ–­ç‚¹ç»­ç»ƒç¤ºä¾‹
    """
    print("\n" + "="*60)
    print("ç®€å•æ–­ç‚¹ç»­ç»ƒæ–¹æ³•")
    print("="*60)
    print("\næ–¹æ³• 1: æ‰‹åŠ¨ä¿®æ”¹æ¨¡å‹è·¯å¾„ï¼ˆæ¨èï¼‰")
    print("  step 1: æ‰“å¼€ train_fred_fusion.py")
    print("  step 2: æ‰¾åˆ° model_path è®¾ç½®")
    print("  step 3: è®¾ç½®ä¸ºæ£€æŸ¥ç‚¹è·¯å¾„:")
    print("    model_path = 'logs/fred_fusion/freeze_epoch_50_weights.pth'")
    print("  step 4: è®¾ç½® Init_Epoch:")
    print("    Init_Epoch = 50")
    print("  step 5: è¿è¡Œè®­ç»ƒ:")
    print("    python train_fred_fusion.py --modality rgb")
    
    print("\næ–¹æ³• 2: ä½¿ç”¨ --resume_lastï¼ˆéœ€å…ˆä¿å­˜æœ€åæ¨¡å‹ï¼‰")
    print("  python train_fred_fusion.py --modality rgb --resume_last")
    
    print("\næ–¹æ³• 3: æ‰¹é‡æ¢å¤è„šæœ¬")
    print("  bash resume_training.sh")


def check_cuda_memory():
    """
    æ£€æŸ¥ CUDA å†…å­˜çŠ¶æ€
    """
    if torch.cuda.is_available():
        device = torch.device('cuda')
        try:
            # æ¸…ç†æ˜¾å­˜
            torch.cuda.empty_cache()
            
            # è·å–æ˜¾å­˜ä¿¡æ¯
            total_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            allocated = torch.cuda.memory_allocated(device) / 1024**3
            reserved = torch.cuda.memory_reserved(device) / 1024**3
            
            print("\n" + "="*60)
            print("CUDA æ˜¾å­˜çŠ¶æ€")
            print("="*60)
            print(f"æ€»æ˜¾å­˜: {total_memory:.2f} GB")
            print(f"å·²åˆ†é…: {allocated:.2f} GB ({allocated/total_memory*100:.1f}%)")
            print(f"å·²ä¿ç•™: {reserved:.2f} GB ({reserved/total_memory*100:.1f}%)")
            print(f"å¯ç”¨æ˜¾å­˜: {total_memory - reserved:.2f} GB")
            
            return total_memory > 8  # è‡³å°‘éœ€è¦ 8GB æ˜¾å­˜
        except:
            return True
    else:
        print("âš ï¸  æœªæ£€æµ‹åˆ° CUDA")
        return False


if __name__ == "__main__":
    # æ£€æŸ¥æ˜¾å­˜
    if not check_cuda_memory():
        print("\nğŸš¨ è­¦å‘Š: æ˜¾å­˜ä¸è¶³ï¼Œæœ€å¤§å¯èƒ½ä¼šå½±å“è®­ç»ƒç¨³å®šæ€§")
        print("å»ºè®®:")
        print("  - å‡å° batch size")
        print("  - å‡å° input_shape")
        print("  - ä½¿ç”¨ --no_eval_map ç¦ç”¨ mAP è¯„ä¼°")
    
    # æ˜¾ç¤ºä½¿ç”¨è¯´æ˜
    simple_resume_example()
    
    # æç¤ºç”¨æˆ·å¦‚ä½•å®é™…ä½¿ç”¨
    print("\n" + "="*60)
    print("ç›´æ¥æ¢å¤è®­ç»ƒçš„æ–¹æ³•")
    print("="*60)
    print("\nåœ¨ train_fred_fusion.py ä¸­æ·»åŠ ä»¥ä¸‹ä»£ç :")
    print("""
# åŠ è½½æ£€æŸ¥ç‚¹
if args.checkpoint_path:
    print(f"åŠ è½½æ£€æŸ¥ç‚¹: {args.checkpoint_path}")
    checkpoint = torch.load(args.checkpoint_path, map_location='cpu')
    model_train.load_state_dict(checkpoint['model'])
    if ema:
        ema.ema.load_state_dict(checkpoint['ema'])
    print(f"æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸ")
    
    # è·å–æ¢å¤ epoch
    Init_Epoch = checkpoint['epoch']
    UnFreeze_Epoch = max(UnFreeze_Epoch, Init_Epoch + 1)
""")