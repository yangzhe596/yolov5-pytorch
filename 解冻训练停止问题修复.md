# Fusion æ¨¡å‹è§£å†»è®­ç»ƒåœæ­¢é—®é¢˜ä¿®å¤æ€»ç»“

## ğŸš¨ é—®é¢˜æè¿°

**é—®é¢˜**: `train_fred_fusion.py` åœ¨è®­ç»ƒåˆ° 50 è½®è§£å†»æ—¶ä¼šåœæ­¢

**ç°è±¡**: 
- å†»ç»“è®­ç»ƒé˜¶æ®µ (0-50 epoch) æ­£å¸¸è¿è¡Œ
- è¿›å…¥è§£å†»è®­ç»ƒé˜¶æ®µæ—¶ç¨‹åºåœæ­¢æˆ–æŠ¥é”™
- æ²¡æœ‰é”™è¯¯ä¿¡æ¯æˆ–å´©æºƒæ—¥å¿—

## ğŸ” é—®é¢˜åˆ†æ

### æ ¹æœ¬åŸå› 

åœ¨ `train_fred_fusion.py` ä¸­å‘ç°äº† **ä¸¤ä¸ªå…³é”®é—®é¢˜**ï¼š

#### 1. Scaler æœªæ­£ç¡®åˆå§‹åŒ–ï¼ˆä¸»è¦é—®é¢˜ï¼‰

**ä½ç½®**: ç¬¬ 1011-1095 è¡Œï¼ˆè§£å†»è®­ç»ƒé˜¶æ®µï¼‰

**é—®é¢˜ä»£ç **:
```python
# é”™è¯¯ï¼šä¼ å…¥ None è€Œä¸æ˜¯åˆ›å»ºæ–°çš„ scaler
fit_one_epoch_fusion(..., scaler=None, ...)
```

**åŸå› **: 
- å†»ç»“è®­ç»ƒé˜¶æ®µåˆ›å»ºäº† `scaler`
- è§£å†»è®­ç»ƒé˜¶æ®µä¼ å…¥ `None` ä½† `fit_one_epoch_fusion` ä»ç„¶å°è¯•ä½¿ç”¨ scaler
- å¯¼è‡´ `AttributeError: 'NoneType' object has no attribute 'scale'`

#### 2. Scalar æ¡ä»¶åˆ¤æ–­é”™è¯¯

**ä½ç½®**: ç¬¬ 420-473 è¡Œï¼ˆ`fit_one_epoch_fusion` å‡½æ•°ï¼‰

**é—®é¢˜ä»£ç **:
```python
if not fp16:
    # æ­£å¸¸è®­ç»ƒ
    ...
else:
    # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆä½† scaler å¯èƒ½ä¸º Noneï¼ï¼‰
    scaler.scale(loss_value_all).backward()  # âŒ å´©æºƒï¼
    scaler.step(optimizer)
    scaler.update()
```

**åŸå› **: 
- `fp16=True` ä½† `scaler=None` æ—¶ä»å°è¯•ä½¿ç”¨ scaler
- è§£å†»è®­ç»ƒé˜¶æ®µæ²¡æœ‰åˆ›å»º scaler

## âœ… ä¿®å¤æ–¹æ¡ˆ

### ä¿®å¤ 1: æ­£ç¡®åˆå§‹åŒ– Scalerï¼ˆè§£å†»è®­ç»ƒé˜¶æ®µï¼‰

```python
# è§£å†»è®­ç»ƒé˜¶æ®µ
if not args.eval_only:
    if args.freeze_training:
        print("ä»…è¿›è¡Œå†»ç»“è®­ç»ƒï¼Œè·³è¿‡è§£å†»è®­ç»ƒé˜¶æ®µ")
    else:
        print("ç¬¬äºŒé˜¶æ®µï¼šè§£å†»è®­ç»ƒ")
        
        # âœ… ä¿®å¤ï¼šé‡æ–°åˆ›å»º scaler
        scaler = torch.cuda.amp.GradScaler(enabled=fp16)
        
        # å¼€å§‹è®­ç»ƒ
        for epoch in range(Freezed_Epoch, UnFreeze_Epoch):
            fit_one_epoch_fusion(..., scaler=scaler, ...)
```

### ä¿®å¤ 2: æ­£ç¡®çš„æ··åˆç²¾åº¦åˆ¤æ–­

```python
# ä¿®å¤ï¼šåŒæ—¶æ£€æŸ¥ fp16 å’Œ scaler
use_autocast = fp16 and (scaler is not None)

if not use_autocast:
    # æ­£å¸¸è®­ç»ƒæˆ– fp16=False
    outputs = model_train(rgb_images, event_images)
    loss_value_all.backward()
    optimizer.step()
else:
    # æ··åˆç²¾åº¦è®­ç»ƒï¼ˆä¿è¯ scaler ä¸ä¸º Noneï¼‰
    from torch.cuda.amp import autocast
    with autocast():
        outputs = model_train(rgb_images, event_images)
        loss_value_all = ...
    
    scaler.scale(loss_value_all).backward()  # âœ… å®‰å…¨
    scaler.step(optimizer)
    scaler.update()
```

## ğŸ“¦ æ–°å¢åŠŸèƒ½

### 1. æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¿å­˜

**å†»ç»“è®­ç»ƒé˜¶æ®µ** (æ¯ 10 ä¸ª epoch):
```python
if (epoch + 1) % 10 == 0 and local_rank == 0:
    checkpoint = {
        'epoch': epoch + 1,
        'model': model_train.state_dict(),
        'ema': ema.ema.state_dict() if ema else None,
        'optimizer': optimizer.state_dict(),
        'loss': loss_history.losses[-1] if loss_history else 0
    }
    torch.save(checkpoint, 
        os.path.join(save_dir, f'freeze_epoch_{epoch+1}_weights.pth'))
```

**è§£å†»è®­ç»ƒé˜¶æ®µ** (æ¯ 10 ä¸ª epoch):
```python
if (epoch + 1) % 10 == 0 and local_rank == 0:
    checkpoint = {
        'epoch': epoch + 1,
        'model': model_train.state_dict(),
        'ema': ema.ema.state_dict() if ema else None,
        'optimizer': optimizer.state_dict(),
        'loss': loss_history.losses[-1] if loss_history else 0
    }
    torch.save(checkpoint, 
        os.path.join(save_dir, f'unfreeze_epoch_{epoch+1}_weights.pth'))
```

### 2. è§£å†»è®­ç»ƒæ£€æŸ¥ç‚¹åŠ è½½

```python
# å°è¯•åŠ è½½å†»ç»“è®­ç»ƒæ£€æŸ¥ç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
checkpoint_path = os.path.join(save_dir, 'freeze_last_epoch_weights.pth')
if os.path.exists(checkpoint_path):
    print(f"âœ“ å‘ç°æ£€æŸ¥ç‚¹ï¼ŒåŠ è½½å†»ç»“è®­ç»ƒæƒé‡")
    try:
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        model_train.load_state_dict(checkpoint['model'])
        if ema:
            ema.ema.load_state_dict(checkpoint['ema'])
        print(f"âœ“ æ£€æŸ¥ç‚¹åŠ è½½æˆåŠŸï¼Œç»§ç»­è®­ç»ƒ")
    except Exception as e:
        print(f"âš ï¸ æ£€æŸ¥ç‚¹åŠ è½½å¤±è´¥: {e}")
```

### 3. æ–­ç‚¹ç»­ç»ƒå·¥å…·

**æ–­ç‚¹ç»­ç»ƒè„šæœ¬**: `resume_training.sh`

**ä½¿ç”¨æ–¹æ³•**:
```bash
# è‡ªåŠ¨æŸ¥æ‰¾æ£€æŸ¥ç‚¹å¹¶æ¢å¤
./resume_training.sh rgb

# æŒ‡å®šæ¢å¤æ¨¡å¼
./resume_training.sh rgb freeze   # ä»…æ¢å¤å†»ç»“è®­ç»ƒ
./resume_training.sh rgb unfreeze # ä»…æ¢å¤è§£å†»è®­ç»ƒ
```

**Python å·¥å…·**: `resume_training.py`

```bash
# æŸ¥çœ‹ä½¿ç”¨è¯´æ˜
python resume_training.py

# æŸ¥æ‰¾æ£€æŸ¥ç‚¹
python -c "
from resume_training import find_latest_checkpoint
checkpoint = find_latest_checkpoint('logs/fred_rgb', 'unfreeze')
print(f'æœ€æ–°æ£€æŸ¥ç‚¹: {checkpoint}')
"
```

## ğŸ¯ æ¢å¤è®­ç»ƒæ–¹æ³•

### æ–¹æ³• 1: ä½¿ç”¨ä¿®æ”¹åçš„ train_fred_fusion.pyï¼ˆæ¨èï¼‰

ä¸‹è½½ä¿®å¤åçš„ `train_fred_fusion.py`ï¼Œæ›´æ–°ä»¥ä¸‹å†…å®¹ï¼š

1. **ä¿®å¤ Scale åˆå§‹åŒ–**
2. **è‡ªåŠ¨æ£€æŸ¥ç‚¹ä¿å­˜**
3. **æ£€æŸ¥ç‚¹åŠ è½½æ”¯æŒ**

ç„¶åç›´æ¥è¿è¡Œï¼š
```bash
python train_fred_fusion.py --modality rgb
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- æ£€æŸ¥ç°æœ‰æ£€æŸ¥ç‚¹
- é€‰æ‹©æœ€è¿‘çš„æ£€æŸ¥ç‚¹æ¢å¤
- ç»§ç»­è®­ç»ƒ

### æ–¹æ³• 2: æ‰‹åŠ¨æ¢å¤ï¼ˆä¸´æ—¶æ–¹æ¡ˆï¼‰

å¦‚æœæ— æ³•æ›´æ–°ä»£ç ï¼Œå¯ä»¥æ‰‹åŠ¨æ¢å¤ï¼š

#### ç¬¬ä¸€æ­¥: æŸ¥æ‰¾æ£€æŸ¥ç‚¹

```bash
# åˆ—å‡ºæ‰€æœ‰æ£€æŸ¥ç‚¹
ls -lh logs/fred_rgb/*.pth

# ç¤ºä¾‹è¾“å‡º:
# freeze_epoch_50_weights.pth  # å†»ç»“è®­ç»ƒæœ€å
# freeze_epoch_40_weights.pth
# ...
```

#### ç¬¬äºŒæ­¥: ä¿®æ”¹ train_fred_fusion.py

åœ¨ `train_fred_fusion.py` æ–‡ä»¶æœ«å°¾æ·»åŠ ï¼š

```python
# === æ‰‹åŠ¨æ¢å¤è®­ç»ƒ===
import torch

# åŠ è½½æ£€æŸ¥ç‚¹
checkpoint_path = 'logs/fred_rgb/freeze_epoch_50_weights.pth'
if os.path.exists(checkpoint_path):
    print(f"åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
    checkpoint = torch.load(checkpoint_path, map_location='cpu')
    
    # æ¢å¤æ¨¡å‹æƒé‡
    model_train.load_state_dict(checkpoint['model'])
    
    # æ¢å¤ optimizer
    if 'optimizer' in checkpoint:
        optimizer.load_state_dict(checkpoint['optimizer'])
        print("âœ“ æ¢å¤ optimizer çŠ¶æ€")
    
    # æ¢å¤ EMA
    if ema and 'ema' in checkpoint:
        ema.ema.load_state_dict(checkpoint['ema'])
        print("âœ“ æ¢å¤ EMA çŠ¶æ€")
    
    # è®¾ç½®èµ·å§‹ epoch
    Init_Epoch = checkpoint['epoch']
    print(f"âœ“ æ¢å¤åˆ° epoch: {Init_Epoch}")
    
    # è·³è¿‡å†»ç»“è®­ç»ƒï¼Œç›´æ¥è¿›å…¥è§£å†»è®­ç»ƒ
    Freeze_Train = False
```

#### ç¬¬ä¸‰æ­¥: è¿è¡Œè®­ç»ƒ

```bash
python train_fred_fusion.py --modality rgb
```

### æ–¹æ³• 3: ä»å¤´å¼€å§‹ + è·³è¿‡å†»ç»“ï¼ˆç´§æ€¥æ–¹æ¡ˆï¼‰

å¦‚æœæ£€æŸ¥ç‚¹æŸåï¼Œå¯ä»¥ä»å¤´å¼€å§‹ä½†è·³è¿‡å†»ç»“ï¼š

```bash
python train_fred_fusion.py --modality rgb --skip_freeze
```

éœ€è¦åœ¨ä»£ç ä¸­æ·»åŠ  `--skip_freeze` å‚æ•°æ”¯æŒï¼š
```python
parser.add_argument('--skip_freeze', action='store_true', 
                    help='è·³è¿‡å†»ç»“è®­ç»ƒï¼Œç›´æ¥è¿›å…¥è§£å†»')
```

## ğŸ”§ é¢„é˜²æªæ–½

### 1. å¢åŠ æ£€æŸ¥ç‚¹é¢‘ç‡

```python
# ä¿®æ”¹ä¸ºæ¯ 5 ä¸ª epoch ä¿å­˜ä¸€æ¬¡
if (epoch + 1) % 5 == 0:
    save_checkpoint(...)
```

### 2. æ·»åŠ å¼‚å¸¸å¤„ç†

```python
try:
    fit_one_epoch_fusion(...)
except Exception as e:
    print(f"è®­ç»ƒå¼‚å¸¸: {e}")
    # ä¿å­˜æ£€æŸ¥ç‚¹å¹¶é€€å‡º
    save_checkpoint(model_train, epoch)
    print("æ£€æŸ¥ç‚¹å·²ä¿å­˜ï¼Œç¨åæ¢å¤è®­ç»ƒ")
    raise
```

### 3. å®šæœŸéªŒè¯æ¨¡å‹

```python
# æ¯ 10 ä¸ª epoch éªŒè¯ä¸€æ¬¡æ¨¡å‹æ˜¯å¦æ­£å¸¸
if epoch % 10 == 0:
    with torch.no_grad():
        test_output = model_train(test_images, test_events)
        print(f"æ¨¡å‹éªŒè¯é€šè¿‡")
```

### 4. ç›‘æ§æ˜¾å­˜ä½¿ç”¨

```python
import subprocess

def check_memory():
    result = subprocess.run(['nvidia-smi', '--query-gpu=memory.used,memory.free,memory.total', '--format=csv'], 
                          capture_output=True, text=True)
    print(result.stdout)
```

## ğŸ“‹ éªŒè¯ä¿®å¤

### è¿è¡Œæµ‹è¯•

```bash
# 1. æ£€æŸ¥ä»£ç è¯­æ³•
python -m py_compile train_fred_fusion.py

# 2. æŸ¥çœ‹ä¿®å¤åçš„ä»£ç 
grep -A 10 "ç¬¬äºŒé˜¶æ®µï¼šè§£å†»è®­ç»ƒ" train_fred_fusion.py

# 3. éªŒè¯æ£€æŸ¥ç‚¹ä¿å­˜
grep -A 5 "checkpoint = {" train_fred_fusion.py
```

### æœŸæœ›è¾“å‡º

ä¿®å¤ååº”è¯¥èƒ½çœ‹åˆ°ï¼š
- âœ“ è§£å†»è®­ç»ƒé˜¶æ®µé‡æ–°åˆ›å»º scaler
- âœ“ æ¯ 10 ä¸ª epoch ä¿å­˜æ£€æŸ¥ç‚¹
- âœ“ æ”¯æŒæ£€æŸ¥ç‚¹åŠ è½½
- âœ“ æ··åˆç²¾åº¦è®­ç»ƒæ­£ç¡®åˆ¤æ–­

## ğŸ“Š æ–‡ä»¶å˜æ›´

### ä¿®æ”¹çš„æ–‡ä»¶

| æ–‡ä»¶ | å˜æ›´ç±»å‹ | è¯´æ˜ |
|------|---------|------|
| `train_fred_fusion.py` | ä¿®æ”¹ | - ä¿®å¤ scaler åˆå§‹åŒ–<br>- æ·»åŠ æ£€æŸ¥ç‚¹ä¿å­˜<br>- æ”¯æŒæ£€æŸ¥ç‚¹åŠ è½½ |

### æ–°å¢çš„æ–‡ä»¶

| æ–‡ä»¶ | ç±»å‹ | ç”¨é€” |
|------|------|------|
| `resume_training.sh` | Bash è„šæœ¬ | å¿«é€Ÿæ¢å¤è®­ç»ƒ |
| `resume_training.py` | Python å·¥å…· | è¯¦ç»†æ¢å¤å·¥å…· |

## âš ï¸ æ³¨æ„äº‹é¡¹

### 1. æ˜¾å­˜è¦æ±‚

- **å†»ç»“è®­ç»ƒ**: ~6GB æ˜¾å­˜
- **è§£å†»è®­ç»ƒ**: ~10-12GB æ˜¾å­˜
- **å»ºè®®**: ä½¿ç”¨ RTX 3090 (24GB) æˆ–æ›´é«˜é…ç½®

### 2. æ£€æŸ¥ç‚¹å…¼å®¹æ€§

- âœ… å†»ç»“è®­ç»ƒæ£€æŸ¥ç‚¹ â†’ å¯ç”¨äºè§£å†»è®­ç»ƒ
- âœ… è§£å†»è®­ç»ƒæ£€æŸ¥ç‚¹ â†’ å¯ç»§ç»­è§£å†»è®­ç»ƒ
- âŒ ä¸è¦æ··ç”¨ä¸åŒç‰ˆæœ¬çš„ä»£ç 

### 3. è®­ç»ƒç¨³å®šæ€§

- å¦‚æœåœ¨è§£å†»è®­ç»ƒæ—¶ä»ç„¶å´©æºƒï¼š
  ```bash
  # å‡å° batch size
  UNFREEZE_BATCH_SIZE=4  # ä» 8 å‡å°åˆ° 4
  
  # ç¦ç”¨ mAP è¯„ä¼°
  python train_fred_fusion.py --modality rgb --no_eval_map
  ```

## ğŸ‰ é¢„æœŸæ•ˆæœ

ä¿®å¤åï¼Œè®­ç»ƒå°†ï¼š

1. âœ… æ­£å¸¸é€šè¿‡ 50 è½®å†»ç»“è®­ç»ƒ
2. âœ… é¡ºåˆ©è¿›å…¥è§£å†»è®­ç»ƒé˜¶æ®µ
3. âœ… æ­£å¸¸ä¿å­˜æ£€æŸ¥ç‚¹ï¼ˆæ¯ 10 ä¸ª epochï¼‰
4. âœ… å¯ä»¥ä»å´©æºƒç‚¹æ¢å¤è®­ç»ƒ
5. âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [Fusion è¯„ä¼°å›è°ƒæŒ‡å—](utils/FUSION_EVAL_CALLBACK_GUIDE.md)
- [Fusion æ•°æ®åŠ è½½å™¨æŒ‡å—](FUSION_DATALOADER_GUIDE.md)
- [å…¼å®¹æ€§ä¿®å¤è¯´æ˜](FUSION_COMPATIBILITY_FIX.md)

## ğŸ“ å¿«é€Ÿå‚è€ƒ

### ç«‹å³ä¿®å¤

```bash
# ä¸‹è½½ä¿®å¤åçš„ä»£ç 
wget -O train_fred_fusion.py [ä¿®å¤ç‰ˆæœ¬]

# å¼€å§‹è®­ç»ƒ
python train_fred_fusion.py --modality rgb

# å¦‚æœä¸­æ–­ï¼Œæ¢å¤è®­ç»ƒ
./resume_training.sh rgb
```

### æ£€æŸ¥é—®é¢˜

```bash
# æ£€æŸ¥æ˜¯å¦æœ‰æ£€æŸ¥ç‚¹
ls -lh logs/fred_rgb/*.pth

# æŸ¥çœ‹æœ€åçš„è®­ç»ƒæ—¥å¿—
tail -f logs/fred_rgb/loss_*/events.out.tfevents.*
```

---

**ä¿®å¤å®Œæˆæ—¶é—´**: 2025-11-26  
**ä¿®å¤ç‰ˆæœ¬**: v1.2  
**éªŒè¯çŠ¶æ€**: âœ… å·²é€šè¿‡è¯­æ³•æ£€æŸ¥

**ä¸‹ä¸€æ¬¡è®­ç»ƒ**: å°†è‡ªåŠ¨æ”¯æŒæ£€æŸ¥ç‚¹æ¢å¤ï¼Œå»ºè®®ä½¿ç”¨ï¼š
```bash
python train_fred_fusion.py --modality rgb
```