#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä½¿ç”¨FRED COCOæ•°æ®é›†è®­ç»ƒYOLOv5

ä¼˜åŒ–ç‰ˆæœ¬ï¼š
- æ”¹è¿›ä»£ç ç»“æ„å’Œå¯è¯»æ€§
- ä¼˜åŒ–å†…å­˜ä½¿ç”¨å’Œè®¡ç®—æ•ˆç‡
- å¢å¼ºé”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
- æ¨¡å—åŒ–é…ç½®ç®¡ç†
- è‡ªåŠ¨åŒ–èµ„æºç›‘æ§

Author: Optimized Version
Date: 2025-11-21
"""
import argparse
import datetime
import logging
import os
import sys
import time
from functools import partial
from typing import Dict, List, Optional, Tuple, Union

import numpy as np
import torch
import torch.backends.cudnn as cudnn
import torch.distributed as dist
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader

from nets.yolo import YoloBody
from nets.yolo_training import (ModelEMA, YOLOLoss, get_lr_scheduler,
                                set_optimizer_lr, weights_init)
from utils.callbacks import LossHistory
from utils.callbacks_coco import CocoEvalCallback, SimplifiedEvalCallback
from utils.dataloader_coco import CocoYoloDataset, coco_dataset_collate
from utils.utils import (download_weights, get_anchors, get_classes,
                         seed_everything, show_config, worker_init_fn)
from utils.utils_fit import fit_one_epoch

# å¯¼å…¥FREDé…ç½®
import config_fred as cfg

if __name__ == "__main__":
    # å‘½ä»¤è¡Œå‚æ•°
    parser = argparse.ArgumentParser(description='ä½¿ç”¨FRED COCOæ•°æ®é›†è®­ç»ƒYOLOv5')
    parser.add_argument('--modality', type=str, default='rgb', choices=['rgb', 'event'],
                        help='é€‰æ‹©æ¨¡æ€: rgb æˆ– event')
    parser.add_argument('--eval_only', action='store_true', 
                        help='åªè¿›è¡Œè¯„ä¼°ï¼Œä¸è¿›è¡Œè®­ç»ƒ')
    parser.add_argument('--eval_map', action='store_true', default=True,
                        help='æ˜¯å¦è®¡ç®—mAPï¼ˆä¼šå¢åŠ è®­ç»ƒæ—¶é—´ï¼‰')
    parser.add_argument('--no_eval_map', action='store_true',
                        help='ç¦ç”¨mAPè¯„ä¼°ä»¥åŠ å¿«è®­ç»ƒé€Ÿåº¦')
    parser.add_argument('--resume', action='store_true',
                        help='ä»æœ€ä½³æƒé‡ç»§ç»­è®­ç»ƒ')
    parser.add_argument('--quick_test', action='store_true',
                        help='å¿«é€ŸéªŒè¯æ¨¡å¼ï¼šä»…è¿è¡Œ100ä¸ªbatchéªŒè¯åŠŸèƒ½æ­£ç¡®æ€§')
    parser.add_argument('--high_res', action='store_true',
                        help='å¯ç”¨é«˜åˆ†è¾¨ç‡æ¨¡å¼ï¼ˆ160x160, 80x80, 40x40ç‰¹å¾å±‚ï¼‰ï¼Œé€‚ç”¨äºå°ç›®æ ‡æ£€æµ‹')
    parser.add_argument('--four_features', action='store_true',
                        help='å¯ç”¨å››ç‰¹å¾å±‚æ¨¡å¼ï¼ˆP2, P3, P4, P5ï¼‰ï¼Œéœ€è¦åŒæ—¶æŒ‡å®š--high_res')
    args = parser.parse_args()
    
    # å¦‚æœæŒ‡å®šäº† --no_eval_mapï¼Œåˆ™ç¦ç”¨mAPè¯„ä¼°
    if args.no_eval_map:
        args.eval_map = False
    
    modality = args.modality
    
    # ========================================================================
    # åº”ç”¨å‘½ä»¤è¡Œå‚æ•°è¦†ç›–é…ç½®
    # ========================================================================
    
    # é…ç½®é«˜åˆ†è¾¨ç‡æ¨¡å¼
    if args.high_res:
        print("\n" + "="*70)
        if args.four_features:
            print("ğŸ” å››ç‰¹å¾å±‚é«˜åˆ†è¾¨ç‡æ¨¡å¼å·²å¯ç”¨")
        else:
            print("ğŸ” é«˜åˆ†è¾¨ç‡æ¨¡å¼å·²å¯ç”¨")
        print("="*70)
        if args.four_features:
            print("  - ç‰¹å¾å±‚: 160x160, 80x80, 40x40, 20x20")
            print("  - é€‚ç”¨äºå„ç§å°ºå¯¸ç›®æ ‡æ£€æµ‹")
            print("  - ä½¿ç”¨å››ç‰¹å¾å±‚å…ˆéªŒæ¡†")
        else:
            print("  - ç‰¹å¾å±‚: 160x160, 80x80, 40x40")
            print("  - é’ˆå¯¹å°ç›®æ ‡æ£€æµ‹ä¼˜åŒ–")
            print("  - ä½¿ç”¨é«˜åˆ†è¾¨ç‡å…ˆéªŒæ¡†")
        print("="*70 + "\n")
        
        # åº”ç”¨é«˜åˆ†è¾¨ç‡é…ç½®
        anchors_path, anchors_mask = cfg.configure_high_res_mode(True, args.four_features)
    else:
        if args.four_features:
            print("è­¦å‘Š: --four_features éœ€è¦ --high_res å‚æ•°ï¼Œå°†å¿½ç•¥ --four_features")
        anchors_path, anchors_mask = cfg.configure_high_res_mode(False, False)
    
    # ========================================================================
    # ä»é…ç½®æ–‡ä»¶åŠ è½½å‚æ•°
    # ========================================================================
    
    # åŸºæœ¬é…ç½®
    Cuda = cfg.CUDA
    seed = cfg.SEED
    distributed = cfg.DISTRIBUTED
    sync_bn = cfg.SYNC_BN
    fp16 = cfg.FP16
    
    # æ¨¡å‹é…ç½®
    input_shape = cfg.INPUT_SHAPE
    backbone = cfg.BACKBONE
    phi = cfg.PHI
    pretrained = cfg.PRETRAINED
    
    # æ•°æ®é›†è·¯å¾„é…ç½®
    train_json = cfg.get_annotation_path(modality, 'train')
    val_json = cfg.get_annotation_path(modality, 'val')
    test_json = cfg.get_annotation_path(modality, 'test')
    
    train_img_dir = cfg.get_image_dir(modality)
    val_img_dir = cfg.get_image_dir(modality)
    test_img_dir = cfg.get_image_dir(modality)
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(train_json):
        raise FileNotFoundError(f"è®­ç»ƒé›†æ ‡æ³¨æ–‡ä»¶ä¸å­˜åœ¨: {train_json}\n"
                              f"è¯·å…ˆè¿è¡Œ: python convert_fred_to_coco.py --modality {modality}")
    
    # ç±»åˆ«é…ç½®
    num_classes = cfg.NUM_CLASSES
    class_names = cfg.CLASS_NAMES
    
    # å…ˆéªŒæ¡†é…ç½®ï¼ˆå·²åœ¨ä¸Šæ–¹é€šè¿‡high_reså‚æ•°é…ç½®ï¼‰
    # anchors_path, anchors_mask å·²åœ¨ä¸Šé¢é…ç½®
    
    # æ¨¡å‹æƒé‡ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ç»ƒï¼‰
    if args.resume:
        model_path = cfg.get_model_path(modality, best=True)
        if not os.path.exists(model_path):
            print(f"è­¦å‘Š: æœªæ‰¾åˆ°æœ€ä½³æƒé‡ {model_path}ï¼Œå°†ä»å¤´è®­ç»ƒ")
            model_path = ''
    else:
        model_path = ''
    
    # æ•°æ®å¢å¼º
    mosaic = cfg.MOSAIC
    mosaic_prob = cfg.MOSAIC_PROB
    mixup = cfg.MIXUP
    mixup_prob = cfg.MIXUP_PROB
    special_aug_ratio = cfg.SPECIAL_AUG_RATIO
    label_smoothing = cfg.LABEL_SMOOTHING
    
    # è®­ç»ƒå‚æ•°
    Init_Epoch = cfg.INIT_EPOCH
    Freeze_Epoch = cfg.FREEZE_EPOCH
    UnFreeze_Epoch = cfg.UNFREEZE_EPOCH
    Freeze_batch_size = cfg.FREEZE_BATCH_SIZE
    Unfreeze_batch_size = cfg.UNFREEZE_BATCH_SIZE
    Freeze_Train = cfg.FREEZE_TRAIN
    
    # ä¼˜åŒ–å™¨é…ç½®
    Init_lr = cfg.INIT_LR
    Min_lr = cfg.MIN_LR
    optimizer_type = cfg.OPTIMIZER_TYPE
    momentum = cfg.MOMENTUM
    weight_decay = cfg.WEIGHT_DECAY
    lr_decay_type = cfg.LR_DECAY_TYPE
    
    # å…¶ä»–é…ç½®
    save_period = cfg.SAVE_PERIOD
    save_dir = cfg.get_save_dir(modality)
    eval_flag = cfg.EVAL_FLAG
    eval_period = cfg.EVAL_PERIOD
    num_workers = cfg.NUM_WORKERS
    prefetch_factor = cfg.PREFETCH_FACTOR
    persistent_workers = cfg.PERSISTENT_WORKERS
    
    # å¿«é€ŸéªŒè¯æ¨¡å¼
    if args.quick_test:
        print("\n" + "="*70)
        print("âš¡ å¿«é€ŸéªŒè¯æ¨¡å¼")
        print("="*70)
        print("ä»…è¿è¡Œ 2 ä¸ª epochï¼Œæ¯ä¸ª epoch æœ€å¤š 100 ä¸ª batch")
        print("ç”¨äºå¿«é€ŸéªŒè¯è®­ç»ƒæµç¨‹æ˜¯å¦æ­£ç¡®")
        print("="*70 + "\n")
        
        Init_Epoch = 0
        Freeze_Epoch = 1
        UnFreeze_Epoch = 2
        Freeze_Train = True
        eval_flag = True
        eval_period = 1
        save_period = 1
    
    # åˆ›å»ºä¿å­˜ç›®å½•
    os.makedirs(save_dir, exist_ok=True)
    
    # éªŒè¯é…ç½®
    config_errors = cfg.validate_config()
    if config_errors:
        print("é…ç½®éªŒè¯å¤±è´¥:")
        for error in config_errors:
            print(f"  - {error}")
        raise ValueError("é…ç½®é”™è¯¯ï¼Œè¯·æ£€æŸ¥ config_fred.py")
    
    seed_everything(seed)
    
    # è®¾ç½®è®¾å¤‡
    ngpus_per_node = torch.cuda.device_count()
    if distributed:
        dist.init_process_group(backend="nccl")
        local_rank = int(os.environ["LOCAL_RANK"])
        rank = int(os.environ["RANK"])
        device = torch.device("cuda", local_rank)
        if local_rank == 0:
            print(f"[{os.getpid()}] (rank = {rank}, local_rank = {local_rank}) training...")
            print("Gpu Device Count : ", ngpus_per_node)
    else:
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        local_rank = 0
        rank = 0
    
    # è·å–å…ˆéªŒæ¡†
    anchors, num_anchors = get_anchors(anchors_path)
    
    # ä¸‹è½½é¢„è®­ç»ƒæƒé‡
    if pretrained:
        if distributed:
            if local_rank == 0:
                download_weights(backbone, phi)
            dist.barrier()
        else:
            download_weights(backbone, phi)
    
    # åˆ›å»ºæ¨¡å‹
    # å››ç‰¹å¾å±‚æ¨¡å¼éœ€è¦ä¼ é€’four_featureså‚æ•°
    four_features = args.high_res and args.four_features
    model = YoloBody(anchors_mask, num_classes, phi, backbone, pretrained=pretrained, input_shape=input_shape, high_res=args.high_res, four_features=four_features)
    if not pretrained:
        weights_init(model)
    
    if model_path != '' and os.path.exists(model_path):
        if local_rank == 0:
            print(f'åŠ è½½æƒé‡: {model_path}')
        
        model_dict = model.state_dict()
        pretrained_dict = torch.load(model_path, map_location=device)
        load_key, no_load_key, temp_dict = [], [], {}
        
        for k, v in pretrained_dict.items():
            if k in model_dict.keys() and np.shape(model_dict[k]) == np.shape(v):
                temp_dict[k] = v
                load_key.append(k)
            else:
                no_load_key.append(k)
        
        model_dict.update(temp_dict)
        model.load_state_dict(model_dict)
        
        if local_rank == 0:
            print(f"æˆåŠŸåŠ è½½çš„é”®æ•°é‡: {len(load_key)}")
            print(f"æœªåŠ è½½çš„é”®æ•°é‡: {len(no_load_key)}")
    
    # æŸå¤±å‡½æ•°
    # å››ç‰¹å¾å±‚æ¨¡å¼éœ€è¦ä¼ é€’four_featureså‚æ•°
    yolo_loss = YOLOLoss(anchors, num_classes, input_shape, Cuda, anchors_mask, label_smoothing, high_res=args.high_res, four_features=four_features)
    
    # è®°å½•Loss
    if local_rank == 0:
        time_str = datetime.datetime.strftime(datetime.datetime.now(),'%Y_%m_%d_%H_%M_%S')
        log_dir = os.path.join(save_dir, "loss_" + str(time_str))
        loss_history = LossHistory(log_dir, model, input_shape=input_shape)
    else:
        loss_history = None
    
    # æ··åˆç²¾åº¦è®­ç»ƒ
    if fp16:
        from torch.cuda.amp import GradScaler as GradScaler
        scaler = GradScaler()
    else:
        scaler = None
    
    model_train = model.train()
    
    # å¤šå¡åŒæ­¥Bn
    if sync_bn and ngpus_per_node > 1 and distributed:
        model_train = torch.nn.SyncBatchNorm.convert_sync_batchnorm(model_train)
    elif sync_bn:
        print("Sync_bn is not support in one gpu or not distributed.")
    
    if Cuda:
        if distributed:
            model_train = model_train.cuda(local_rank)
            model_train = torch.nn.parallel.DistributedDataParallel(model_train, device_ids=[local_rank], find_unused_parameters=True)
        else:
            model_train = torch.nn.DataParallel(model)
            cudnn.benchmark = True
            model_train = model_train.cuda()
    
    # æƒå€¼å¹³æ»‘
    ema = ModelEMA(model_train)
    
    # åˆ›å»ºæ•°æ®é›†
    print(f"\nåŠ è½½FRED {modality.upper()}æ•°æ®é›†...")
    print(f"  è®­ç»ƒé›†: {train_json}")
    print(f"  éªŒè¯é›†: {val_json}")
    print(f"  æµ‹è¯•é›†: {test_json}")
    
    train_dataset = CocoYoloDataset(
        train_json, train_img_dir, input_shape, num_classes, anchors, anchors_mask,
        epoch_length=UnFreeze_Epoch, mosaic=mosaic, mixup=mixup,
        mosaic_prob=mosaic_prob, mixup_prob=mixup_prob, train=True,
        special_aug_ratio=special_aug_ratio, high_res=args.high_res, four_features=four_features
    )
    
    val_dataset = CocoYoloDataset(
        val_json, val_img_dir, input_shape, num_classes, anchors, anchors_mask,
        epoch_length=UnFreeze_Epoch, mosaic=False, mixup=False,
        mosaic_prob=0, mixup_prob=0, train=False, special_aug_ratio=0, high_res=args.high_res, four_features=four_features
    )
    
    num_train = len(train_dataset)
    num_val = len(val_dataset)
    
    if local_rank == 0:
        print(f"\næ•°æ®é›†ç»Ÿè®¡:")
        print(f"  è®­ç»ƒé›†: {num_train} å¼ å›¾ç‰‡")
        print(f"  éªŒè¯é›†: {num_val} å¼ å›¾ç‰‡")
        print(f"  ç±»åˆ«æ•°: {num_classes}")
        print(f"  æ¨¡æ€: {modality.upper()}")
    
    if local_rank == 0:
        show_config(
            model_path=model_path, input_shape=input_shape,
            Init_Epoch=Init_Epoch, Freeze_Epoch=Freeze_Epoch, UnFreeze_Epoch=UnFreeze_Epoch,
            Freeze_batch_size=Freeze_batch_size, Unfreeze_batch_size=Unfreeze_batch_size,
            Freeze_Train=Freeze_Train, Init_lr=Init_lr, Min_lr=Min_lr,
            optimizer_type=optimizer_type, momentum=momentum, lr_decay_type=lr_decay_type,
            save_period=save_period, save_dir=save_dir, num_workers=num_workers,
            prefetch_factor=prefetch_factor, persistent_workers=persistent_workers,
            num_train=num_train, num_val=num_val,
            high_res=args.high_res, anchors_path=anchors_path, anchors_mask=anchors_mask
        )
        
        # æ£€æŸ¥è®­ç»ƒæ­¥æ•°
        wanted_step = 5e4 if optimizer_type == "sgd" else 1.5e4
        total_step = num_train // Unfreeze_batch_size * UnFreeze_Epoch
        
        if total_step <= wanted_step:
            if num_train // Unfreeze_batch_size == 0:
                raise ValueError('æ•°æ®é›†è¿‡å°ï¼Œæ— æ³•è¿›è¡Œè®­ç»ƒï¼Œè¯·æ‰©å……æ•°æ®é›†ã€‚')
            wanted_epoch = wanted_step // (num_train // Unfreeze_batch_size) + 1
            print(f"\n\033[1;33;44m[Warning] ä½¿ç”¨{optimizer_type}ä¼˜åŒ–å™¨æ—¶ï¼Œå»ºè®®å°†è®­ç»ƒæ€»æ­¥é•¿è®¾ç½®åˆ°{wanted_step}ä»¥ä¸Šã€‚\033[0m")
            print(f"\033[1;33;44m[Warning] æœ¬æ¬¡è¿è¡Œçš„æ€»è®­ç»ƒæ•°æ®é‡ä¸º{num_train}ï¼ŒUnfreeze_batch_sizeä¸º{Unfreeze_batch_size}ï¼Œå…±è®­ç»ƒ{UnFreeze_Epoch}ä¸ªEpochï¼Œè®¡ç®—å‡ºæ€»è®­ç»ƒæ­¥é•¿ä¸º{total_step}ã€‚\033[0m")
            print(f"\033[1;33;44m[Warning] ç”±äºæ€»è®­ç»ƒæ­¥é•¿ä¸º{total_step}ï¼Œå°äºå»ºè®®æ€»æ­¥é•¿{wanted_step}ï¼Œå»ºè®®è®¾ç½®æ€»ä¸–ä»£ä¸º{wanted_epoch}ã€‚\033[0m")
    
    # å¼€å§‹è®­ç»ƒ
    if True:
        UnFreeze_flag = False
        
        # å†»ç»“è®­ç»ƒ
        if Freeze_Train:
            for param in model.backbone.parameters():
                param.requires_grad = False
        
        batch_size = Freeze_batch_size if Freeze_Train else Unfreeze_batch_size
        
        # è‡ªé€‚åº”è°ƒæ•´å­¦ä¹ ç‡
        nbs = 64
        lr_limit_max = 1e-3 if optimizer_type == 'adam' else 5e-2
        lr_limit_min = 3e-4 if optimizer_type == 'adam' else 5e-4
        Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)
        Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)
        
        # ä¼˜åŒ–å™¨
        pg0, pg1, pg2 = [], [], []
        for k, v in model.named_modules():
            if hasattr(v, "bias") and isinstance(v.bias, nn.Parameter):
                pg2.append(v.bias)
            if isinstance(v, nn.BatchNorm2d) or "bn" in k:
                pg0.append(v.weight)
            elif hasattr(v, "weight") and isinstance(v.weight, nn.Parameter):
                pg1.append(v.weight)
        
        optimizer = {
            'adam': optim.Adam(pg0, Init_lr_fit, betas=(momentum, 0.999)),
            'sgd': optim.SGD(pg0, Init_lr_fit, momentum=momentum, nesterov=True)
        }[optimizer_type]
        optimizer.add_param_group({"params": pg1, "weight_decay": weight_decay})
        optimizer.add_param_group({"params": pg2})
        
        # å­¦ä¹ ç‡è°ƒåº¦å™¨
        lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)
        
        # è®¡ç®—epochæ­¥æ•°
        epoch_step = num_train // batch_size
        epoch_step_val = num_val // batch_size
        
        if epoch_step == 0 or epoch_step_val == 0:
            raise ValueError("æ•°æ®é›†è¿‡å°ï¼Œæ— æ³•ç»§ç»­è¿›è¡Œè®­ç»ƒï¼Œè¯·æ‰©å……æ•°æ®é›†ã€‚")
        
        if ema:
            ema.updates = epoch_step * Init_Epoch
        
        # æ•°æ®åŠ è½½å™¨
        if distributed:
            train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset, shuffle=True)
            val_sampler = torch.utils.data.distributed.DistributedSampler(val_dataset, shuffle=False)
            batch_size = batch_size // ngpus_per_node
            shuffle = False
        else:
            train_sampler = None
            val_sampler = None
            shuffle = True
        
        gen = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size, 
                        num_workers=num_workers, pin_memory=True, drop_last=True,
                        collate_fn=coco_dataset_collate, sampler=train_sampler,
                        worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed),
                        prefetch_factor=prefetch_factor if num_workers > 0 else None,
                        persistent_workers=persistent_workers if num_workers > 0 else False)
        
        gen_val = DataLoader(val_dataset, shuffle=shuffle, batch_size=batch_size,
                            num_workers=num_workers, pin_memory=True, drop_last=True,
                            collate_fn=coco_dataset_collate, sampler=val_sampler,
                            worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed),
                            prefetch_factor=prefetch_factor if num_workers > 0 else None,
                            persistent_workers=persistent_workers if num_workers > 0 else False)
        
        # è¯„ä¼°å›è°ƒï¼ˆä½¿ç”¨æµ‹è¯•é›†ï¼‰
        if local_rank == 0:
            # å¿«é€ŸéªŒè¯æ¨¡å¼ï¼šé™åˆ¶è¯„ä¼°æ ·æœ¬æ•°é‡
            max_eval_samples = 100 if args.quick_test else None
            
            # æ ¹æ®å‘½ä»¤è¡Œå‚æ•°å†³å®šæ˜¯å¦ä½¿ç”¨å®Œæ•´çš„mAPè¯„ä¼°
            if args.eval_map and eval_flag:
                eval_callback = CocoEvalCallback(
                    net=model,
                    input_shape=input_shape,
                    anchors=anchors,
                    anchors_mask=anchors_mask,
                    class_names=class_names,
                    num_classes=num_classes,
                    coco_json_path=test_json,
                    image_dir=test_img_dir,
                    log_dir=log_dir,
                    cuda=Cuda,
                    map_out_path=os.path.join(save_dir, ".temp_map_out"),
                    max_boxes=cfg.MAX_BOXES,
                    confidence=cfg.CONFIDENCE,
                    nms_iou=cfg.NMS_IOU,
                    letterbox_image=cfg.LETTERBOX_IMAGE,
                    MINOVERLAP=cfg.MINOVERLAP,
                    eval_flag=eval_flag,
                    period=eval_period,
                    max_eval_samples=max_eval_samples
                )
                print("\nâœ“ ä½¿ç”¨COCOæ ¼å¼çš„mAPè¯„ä¼°ï¼ˆä¼šå¢åŠ è®­ç»ƒæ—¶é—´ï¼‰")
                print(f"  - è¯„ä¼°å‘¨æœŸ: æ¯ {eval_period} ä¸ªepoch")
                print(f"  - è¯„ä¼°æ•°æ®é›†: æµ‹è¯•é›† ({test_json})")
                if max_eval_samples:
                    print(f"  - âš¡ å¿«é€ŸéªŒè¯: ä»…è¯„ä¼° {max_eval_samples} ä¸ªæ ·æœ¬")
            else:
                # ä½¿ç”¨ç®€åŒ–ç‰ˆå›è°ƒï¼ˆåªè®°å½•epochï¼Œä¸è®¡ç®—mAPï¼‰
                eval_callback = SimplifiedEvalCallback(log_dir, eval_flag=False, period=1)
                print("\næ³¨æ„: mAPè¯„ä¼°å·²ç¦ç”¨ï¼ˆä½¿ç”¨ --no_eval_map ç¦ç”¨ï¼Œé»˜è®¤å¯ç”¨ï¼‰")
                print("  - å¦‚éœ€åŠ å¿«è®­ç»ƒé€Ÿåº¦ï¼Œå¯ä½¿ç”¨: python train_fred.py --no_eval_map")
        else:
            eval_callback = SimplifiedEvalCallback(log_dir, eval_flag=False, period=1)
        
        # è®­ç»ƒå¾ªç¯
        if args.eval_only:
            print("\nä»…è¯„ä¼°æ¨¡å¼ï¼ˆåŠŸèƒ½å¾…å®ç°ï¼‰")
        else:
            print(f"\nå¼€å§‹è®­ç»ƒ - {modality.upper()}æ¨¡æ€")
            print("=" * 70)
            
            for epoch in range(Init_Epoch, UnFreeze_Epoch):
                # è§£å†»è®­ç»ƒ
                if epoch >= Freeze_Epoch and not UnFreeze_flag and Freeze_Train:
                    batch_size = Unfreeze_batch_size
                    
                    nbs = 64
                    lr_limit_max = 1e-3 if optimizer_type == 'adam' else 5e-2
                    lr_limit_min = 3e-4 if optimizer_type == 'adam' else 5e-4
                    Init_lr_fit = min(max(batch_size / nbs * Init_lr, lr_limit_min), lr_limit_max)
                    Min_lr_fit = min(max(batch_size / nbs * Min_lr, lr_limit_min * 1e-2), lr_limit_max * 1e-2)
                    
                    lr_scheduler_func = get_lr_scheduler(lr_decay_type, Init_lr_fit, Min_lr_fit, UnFreeze_Epoch)
                    
                    for param in model.backbone.parameters():
                        param.requires_grad = True
                    
                    epoch_step = num_train // batch_size
                    epoch_step_val = num_val // batch_size
                    
                    if epoch_step == 0 or epoch_step_val == 0:
                        raise ValueError("æ•°æ®é›†è¿‡å°ï¼Œæ— æ³•ç»§ç»­è¿›è¡Œè®­ç»ƒï¼Œè¯·æ‰©å……æ•°æ®é›†ã€‚")
                    
                    if ema:
                        ema.updates = epoch_step * epoch
                    
                    if distributed:
                        batch_size = batch_size // ngpus_per_node
                    
                    gen = DataLoader(train_dataset, shuffle=shuffle, batch_size=batch_size,
                                    num_workers=num_workers, pin_memory=True, drop_last=True,
                                    collate_fn=coco_dataset_collate, sampler=train_sampler,
                                    worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed),
                                    prefetch_factor=prefetch_factor if num_workers > 0 else None,
                                    persistent_workers=persistent_workers if num_workers > 0 else False)
                    
                    gen_val = DataLoader(val_dataset, shuffle=shuffle, batch_size=batch_size,
                                        num_workers=num_workers, pin_memory=True, drop_last=True,
                                        collate_fn=coco_dataset_collate, sampler=val_sampler,
                                        worker_init_fn=partial(worker_init_fn, rank=rank, seed=seed),
                                        prefetch_factor=prefetch_factor if num_workers > 0 else None,
                                        persistent_workers=persistent_workers if num_workers > 0 else False)
                    
                    UnFreeze_flag = True
                
                gen.dataset.epoch_now = epoch
                gen_val.dataset.epoch_now = epoch
                
                if distributed:
                    train_sampler.set_epoch(epoch)
                
                set_optimizer_lr(optimizer, lr_scheduler_func, epoch)
                
                # å¿«é€ŸéªŒè¯æ¨¡å¼ï¼šé™åˆ¶batchæ•°é‡
                max_batches = 100 if args.quick_test else None
                fit_one_epoch(model_train, model, ema, yolo_loss, loss_history, eval_callback,
                            optimizer, epoch, epoch_step, epoch_step_val, gen, gen_val,
                            UnFreeze_Epoch, Cuda, fp16, scaler, save_period, save_dir, local_rank, max_batches=max_batches)
                
                if distributed:
                    dist.barrier()
            
            if local_rank == 0:
                loss_history.writer.close()
                
                # ä¿å­˜æœ€ç»ˆæ¨¡å‹
                final_model_path = cfg.get_model_path(modality, best=False)
                torch.save(model.state_dict(), final_model_path)
                print(f"\nè®­ç»ƒå®Œæˆï¼æœ€ç»ˆæ¨¡å‹å·²ä¿å­˜: {final_model_path}")
